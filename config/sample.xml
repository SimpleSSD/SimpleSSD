<!-- SPDX-License-Identifier: GPL-3.0-or-later -->
<!--
  Copyright (C) 2019 CAMELab

  Author: Donghyun Gouk <kukdh1@camelab.org>
 -->

<?xml version="1.0" encoding="UTF-8" ?>
<!--
  SimpleSSD configuration file.

  Attribute name is case-sensitive.
 -->
<simplessd version="2.1-unknown">
  <!--
    Rule of values

    str:   String, a sequence of alphanumeric characters
    int:   SI integer, a sequence of numeric characters
           Possible suffix (case sensitive):
            10^3 base: k, m, g, t
            2^10 base: K, M, G, T
    float: Floating point number, a sequence of numeric characters
           with one (or none) of decimal point
    bool:  Boolean, a true or false value.
           Possible value (case insensitive):
            True: Non-zero number, T, True, Y, Yes
            False: Otherwise
    time:  SI integer, a sequenced of numeric characters
           If no suffix provided, value will treated as pico-second.
           Possible suffix (case sensitive):
            s, ms, us, ns, ps
   -->
  <!--
    CPU configuration
   -->
  <section name="cpu">
    <!-- <int> CPU clock speed in Hz -->
    <config name="ClockSpeed">400m</config>
    <!--
      <bool> Use dedicated core

      If true, each firmware components runs on dedicated core(s).
      If not, all firmware components shares all cores.
     -->
    <config name="UseDedicatedCore">true</config>
    <!-- <int> # cores for Host Interface (HIL) -->
    <config name="HILCoreCount">1</config>
    <!-- <int> # cores for Data Cache (ICL) -->
    <config name="ICLCoreCount">1</config>
    <!-- <int> # cores for Flash Translation Layer (FTL) -->
    <config name="FTLCoreCount">1</config>
  </section>
  <!--
    Memory subsystem configuration.
   -->
  <section name="memory">
    <!-- SRAM -->
    <section name="sram">
      <!-- <int> Total size of SRAM -->
      <config name="Size">8M</config>
      <!-- <int> Access latency of SRAM in cycle -->
      <config name="Latency">20</config>
      <!-- <int> Access granularity in bytes (for latency calculation) -->
      <config name="LineSize">8</config>
    </section>
    <!-- DRAM -->
    <section name="dram">
      <!--
        <int> DRAM model.

        Possible values:
         0: Simple DRAM model based on atomic dram controller of gem5
         1: DRAM model based on timing dram controller of gem5
       -->
      <config name="Model">0</config>
      <!-- DRAM structural configuration -->
      <section name="struct">
        <!-- <int> # Channel -->
        <config name="Channel">1</config>
        <!-- <int> # Rank / Channel -->
        <config name="Rank">1</config>
        <!-- <int> # Bank / Rank -->
        <config name="Bank">8</config>
        <!-- <int> # Chip / Rank -->
        <config name="Chip">1</config>
        <!-- <int> # Bus width / Chip -->
        <config name="BusWidth">32</config>
        <!-- <int> # Burst length -->
        <config name="BurstLength">8</config>
        <!-- <int> # Chip size in bytes -->
        <config name="ChipSize">1073741824</config>
      </section>
      <!--
        DRAM timing configuration
        All values in <time>
       -->
      <section name="timing">
        <config name="tCK">1250</config>
        <config name="tRCD">13750</config>
        <config name="tCL">13750</config>
        <config name="tRP">13750</config>
        <config name="tRAS">35000</config>
        <config name="tWR">15000</config>
        <config name="tRTP">7500</config>
        <config name="tBURST"></config>
        <config name="tCCD_L"></config>
        <config name="tCCD_L_WR"></config>
        <config name="tRFC">160000</config>
        <config name="tREFI">7800000</config>
        <config name="tWTR">7500</config>
        <config name="tRTW"></config>
        <config name="tCS"></config>
        <config name="tRRD">6000</config>
        <config name="tRRD_L"></config>
        <config name="tXAW"></config>
        <config name="tXP">6000</config>
        <config name="tXPDLL">24000</config>
        <config name="tXS">170000</config>
        <config name="tXSDLL">640000</config>
      </section>
      <!--
        DRAM power configuration
        All values in <float>, current in mA, voltage in V.
       -->
      <section name="power">
        <config name="IDD0_0">40</config>
        <config name="IDD0_1">0</config>
        <config name="IDD2P0_0">12</config>
        <config name="IDD2P0_1">0</config>
        <config name="IDD2P1_0">14</config>
        <config name="IDD2P1_1">0</config>
        <config name="IDD2N_0">21</config>
        <config name="IDD2N_1">0</config>
        <config name="IDD3P0_0">21</config>
        <config name="IDD3P0_1">0</config>
        <config name="IDD3P1_0">21</config>
        <config name="IDD3P1_1">0</config>
        <config name="IDD3N_0">34</config>
        <config name="IDD3N_1">0</config>
        <config name="IDD4R_0">100</config>
        <config name="IDD4R_1">0</config>
        <config name="IDD4W_0">105</config>
        <config name="IDD4W_1">0</config>
        <config name="IDD5_0">182</config>
        <config name="IDD5_1">0</config>
        <config name="IDD6_0">12</config>
        <config name="IDD6_1">0</config>
        <config name="VDD_0">1.350</config>
        <config name="VDD_1">0</config>
      </section>
      <!--
        gem5's DRAM controller configuration
       -->
      <section name="gem5">
        <!-- <int> Number of write queue entries -->
        <config name="WriteBufferSize">64</config>
        <!-- <int> Number of read queue entries -->
        <config name="ReadBufferSize">64</config>
        <!-- <float> Threshold to force writes -->
        <config name="ForceWriteThreshold">0.85</config>
        <!-- <float> Threshold to start writes -->
        <config name="WriteThreshold">0.5</config>
        <!-- <int> Minimum write bursts before switching to reads -->
        <config name="MinWriteBurst">16</config>
        <!--
          <int> Memory scheduling policy

          Possible values:
            0: FCFS: First come first serve
            1: FR-FCFS: First row-hit then first come first serve
         -->
        <config name="Scheduling">1</config>
        <!--
          <int> Address mapping policy

          Possible values:
            0: RoRaBaChCo: Row > Rank > Bank > Channel > Column (LSB)
            1: RoRaBaCoCh: Row > Rank > Bank > Column > Channel
            2: RoCoRaBaCh: Row > Column > Rank > Bank > Channel
         -->
        <config name="Mapping">1</config>
        <!--
          <int> Page management policy

          Possible values:
            0: Open
            1: Open adaptive
            2: Close
            3: Close adaptive
         -->
        <config name="PagePolicy">1</config>
        <!-- <int> Max accesses per row before closing -->
        <config name="MaxAccessPerRow">16</config>
        <!-- <time> Static frontend latency -->
        <config name="FrontendLatency">10ns</config>
        <!-- <time> Static backend latency -->
        <config name="BackendLatency">10ns</config>
        <!-- <int> Page (row buffer) size per device/chip -->
        <config name="RowbufferSize">4096</config>
        <!-- <int> Number of bank groups per rank -->
        <config name="BankGroup">0</config>
        <!-- <bool> Enable powerdown state -->
        <config name="EnablePowerdown">false</config>
        <!-- <bool> DRAM has DLL or not -->
        <config name="DLL">false</config>
      </section>
    </section>
  </section>
  <!--
    Host Interface Layer configuration
   -->
  <section name="hil">
    <!-- <time> Request collection interval -->
    <config name="WorkInterval">1us</config>
    <!-- <int> Internal request queue size -->
    <config name="RequestQueueSize">8</config>
    <!--
      Interface and bus configuration

      NVMe uses "pcie" and "axi"
       PCIe RC -> PCIe -> PCIe EP -> AXI (SSD memory bus)
      SATA uses "pcie", "sata" and "axi"
       PCIe RC -> PCIe -> HBA -> SATA -> SATA PHY -> AXI (SSD memory bus)
      UFS uses "mphy" and "axi"
       System bus -> UFSHCI -> MPHY -> PHY -> AXI (SSD memory bus)
     -->
    <section name="interface">
      <!-- PCIe configuration -->
      <section name="pcie">
        <!-- <int> PCIe Generation (1 ~ 3) -->
        <config name="Generation">3</config>
        <!-- <int> PCIe Lane (1 ~ 32, power of 2) -->
        <config name="Lane">4</config>
      </section>
      <!-- SATA configuration -->
      <section name="sata">
        <!-- <int> SATA Generation (1 ~ 3) -->
        <config name="Generation">3</config>
      </section>
      <!-- MIPI M-PHY configuration -->
      <section name="mphy">
        <!--
          <int> MIPI M-PHY Mode

          Possible values:
           0: HS-G1 (High Speed Gear 1)
           1: HS-G2
           2: HS-G3
           3: HS-G4
         -->
         <config name="Mode">2</config>
         <!-- <int> M-PHY Lane (1 ~ 2) -->
         <config name="Lane">2</config>
      </section>
      <!-- AXI4 configuration -->
      <section name="axi">
        <!-- <int> AXI bus width (32 ~ 1024, power of 2) -->
        <config name="Width">256</config>
        <!-- <int> AXI bus speed in Hz -->
        <config name="Clock">100m</config>
      </section>
    </section>
    <!--
      Disk configuration

      When using NVMe interface, "nsid" attribute specifies corresponding
      Namespace ID.
      When using other interfaces, only "nsid=1" section will be used.
     -->
    <section name="disk" nsid="1">
      <!-- <bool> Enable disk image mount -->
      <config name="EnableDiskImage">false</config>
      <!--
        <bool> Strick size checking

        If true, you must specify disk image which has exactly same size with
        current volume size.
       -->
      <config name="StrickSizecheck">false</config>
      <!--
        <bool> Use copy-on-write mode

        If true, data written to this volume will not saved to disk image.
        Set true when you simulate multiple instances with a disk image.
        Set false when you are creating disk image for simulation.
       -->
      <config name="UseCopyOnWriteDisk">true</config>
      <!-- <str> Path to disk image -->
      <config name="DiskImagePath"></config>
    </section>
    <!--
      NVMe specific configuration
     -->
    <section name="nvme">
      <!-- <int> Maximum number of submission queues -->
      <config name="MaxSQ">16</config>
      <!-- <int> Maximum number of completion queues -->
      <config name="MaxCQ">16</config>
      <!--
        <int> Weighted Round Robin High Priority

        Specify maximum number of high priority requests should be inserted
        before handling medium priority requests.
       -->
      <config name="WRRHigh">2</config>
      <!--
        <int> Weighted Round Robin Medium Priority

        Specify maximum number of medium priority requests should be inserted
        before handling low priority requests.
       -->
      <config name="WRRMedium">2</config>
      <!-- <int> Maximum number of namespaces supported by controller -->
      <config name="MaxNamespace">16</config>
      <!--
        <int> Initial number of namespaces

        Specify number of namespaces to create at beginning. You must specify
        per-namespace configuration sections.
       -->
      <config name="DefaultNamespace">1</config>
      <!--
        <bool> Attach default namespaces to first controller

        Specify true if you want to attach all default namespaces to first NVMe
        controller (which has controller ID 0). If false, you need to attach by
        Namespace Attachment admin command.
       -->
      <config name="AttachDefaultNamespaces">true</config>
      <!--
        Per-namespace configuration

        You may want to add disk section per namespace.
       -->
      <section name="namespace" nsid="1">
        <!--
          <int> Logical Block size

          Must be power of 2, greater than and equal to 512. In Linux, logical
          block size greater than page size (usually 4K) is not supported.
         -->
        <config name="LBASize">512</config>
        <!--
          <int> Capacity in bytes

          Specify 0 to create evenly divided namespaces. This valus should be
          aligned with LBASize.
         -->
        <config name="Capacity">0</config>
      </section>
    </section>
  </section>
  <!--
    Internal Cache Layer configuration
   -->
  <section name="icl">
    <!-- <bool> Enable caching -->
    <config name="EnableCache">true</config>
    <!-- <bool> Enable read prefetching / read-ahead -->
    <config name="EnableReadPrefetch">true</config>
    <!--
      <int> Prefetch/Read-ahead granularity

      Set quantity of data to read when prefetch/read-ahead triggered.
      For the definition of parallelism group, see FIL section.

      Possible values:
        0: Superpage granularity
        1: Each page in all parallelism group
     -->
    <config name="PrefetchMode">0</config>
    <!--
      <int> Prefetch/read-ahead trigger condition - request count

      Set the number of consecutive sequential read request to trigger
      prefetch/read-ahead. This value should be larger than 1.
     -->
    <config name="PrefetchCount">4</config>
    <!--
      <int> Prefetch/read-ahead trigger condition - read capacity

      Set the amount of data should be read in sequential to trigger
      prefetch/read-ahead. This value is unit of one physical page.
     -->
    <config name="PrefetchRatio">32</config>
    <!--
      <int> Cache algorithm

      Possible values:
        0: Ring buffer
     -->
    <config name="CacheMode">0</config>
    <!-- <int> Cache size in bytes -->
    <config name="CacheSize">512M</config>
    <!--
      <int> Cache eviction policy

      Possible values:
        0: RANDOM: Evict random entry
        1: FIFO: Evict least recently added entry
        2: LRU: Evict least recently used entry
     -->
    <config name="EvictPolicy">2</config>
    <!--
      <int> Eviction granularity

      Set quantity of data to evict when capacity/confilct miss occurs.
      Cache will try to collect as many pages as it can.

      Possible values:
        0: Superpage granularity
        1: Each page in all parallelism group
     -->
    <config name="EvictMode">1</config>
  </section>
  <!--
    Flash Translation Layer configuration
   -->
  <section name="ftl">
    <!--
      <int> Mapping algorithm

      Select FTL mapping algorithm

      Possible values:
        0: Page-level Mapping (Supports superpage)
        1: Block-level Mapping
        2: Virtually-Linked FTL (Extended version of FTL released with Amber)
     -->
    <config name="MappingMode">2</config>
    <!-- Garbage Collection configuration -->
    <section name="gc">
      <!--
        <int> Victim block selection algorithm

        Possible values:
          0: Greedy: Choose lease utilized block (lease number of valid pages).
          1: Cost-Benefit: Choose block that has lowest value of equation:
             utilization / ((1 - utilization) * age)
          2: Random: Choose random block
          3: D-Choice: Choose lease utilized block in randomly sampled blocks
       -->
      <config name="VictimSelectionPolicy">0</config>
      <!--
        <int> D-Choice parameter

        Sampling factor. (blocks to erase) * (this config value) blocks will
        randomly sampled.
       -->
      <config name="DChoiceParam">3</config>
      <!--
        <float> GC triggering threshold

        If the number of free blocks left < (this config value) * (total blocks)
        On-demand GC (Foreground GC) will triggered.
       -->
      <config name="GCThreshold">0.05</config>
      <!--
        <int> Victim block count selection policy

        Possible values:
          0: Reclaim #GCReclaimBlocks blocks
          1: Reclaim blocks until GCReclaimThreshold
       -->
      <config name="GCMode">0</config>
      <!-- <int> # blocks to reclaim -->
      <config name="GCReclaimBlocks">1</config>
      <!-- <int> threshold until reclaim (See GCThresold for definition) -->
      <config name="GCReclaimThreshold">0.1</config>
    </section>
    <!--
      Common FTL algorithm configurations

      May not applied to hybrid-FTL
     -->
    <section name="common">
      <!--
        <float> Overprovisioning Ratio

        Select OP ratio (ratio between user-visible logical range and physical NVM
        range). (1 - this value) * (total SSD size) become user-visible range.

        This value will rounded to FTL mapping granularity.
       -->
      <config name="OverProvisioningRatio">0.2</config>
      <!--
        <int> Bad block threshold

        Set P/E cycle threshold to mark block as bad.

        TODO: Add error model and change this value to BER or ECC retry count.
       -->
      <config name="EraseThreshold">100k</config>
      <!--
        <bool> Use superpage

        Superpage can be used to reduce size of mapping table by grouping pages
        in same parallelism group. See PageAllocation for more details on
        parallelism group.
       -->
      <config name="UseSuperpage">true</config>
      <!--
        <str> Superpage configuration

        Specify level of parallelism group to group pages in one super page.
        Example) Specify 'C' to group a page in same page index in different
        channel.
       -->
      <config name="SuperpageAllocation">C</config>
      <!-- Filling/Warm-up configuration -->
      <section name="warmup">
        <!--
          <int> Filling Mode

          Here, we have two-pass filling algorithm to invoke GC in very beginning
          of simulation. In first pass, FTL fills mapping - clean write. In second
          pass, FTL overwrites pages written in first pass which makes invalid
          pages.

          Possible values:
            0: Sequential filling + Sequential invalidation
            1: Sequential filling + Random invalidation
            2: Random filling + Random invalidation
         -->
        <config name="FillingMode">0</config>
        <!--
          <float> Range to fill in first pass

          In sequential filling, LPN from 0 to (this config value) * (SSD size)
          will be filled.
          In random filling, (this config value) * (total physical page count)
          physical pages will be filled in random fashion. Because of memory
          requirement, we does not ensure unique random address - overwritten can
          be occur in first pass.
         -->
        <config name="FillRatio">1.0</config>
        <!--
          <float> Range to fill in second pass

          Try to overwrite page written in first pass. If you use random address,
          some pages will not overwritten as we don't remember what addresses are
          written.

          This valud will clipped to make GC not occured in warm-up phase.
         -->
        <config name="InvalidFillRatio">0.0</config>
      </section>
    </section>
    <!-- VLFTL configuration -->
    <section name="vlftl">
      <!-- <float> Ratio of partial-mapping table -->
      <section name="VLTableRatio">0.3</section>
      <!-- <float> Merge threshold -->
      <section name="MergeBeginThreshold">0.1</section>
      <!-- <float> Merge terminate threshold -->
      <section name="MergeEndThreshold">0.2</section>
      <!-- Other param follows GC setting -->
    </section>
  </section>
  <!--
    Flash Interface Layer configuration
   -->
  <section name="fil">
    <!-- <int> # channel -->
    <config name="Channel">8</config>
    <!-- <int> # packages / channel (way) -->
    <config name="Way">4</config>
    <!--
      <int> Channel speed

      Specify channel speed in transfers / second (T/s)
      One transfer has size of DMAWidth.
     -->
    <config name="DMASpeed">200m</config>
    <!-- <int> Channel width -->
    <config name="DMAWidth">8</config>
    <!--
      <int> Select NVM model

      Possible values:
        0: PAL: Parallelism Abstraction Layer in SimpleSSD 1.0 ~ 2.0
        1: NAND: Generic NAND flash
     -->
    <config name="Model">0</config>
    <!-- NAND configuration (valid for Model = 0/1) -->
    <section name="nand">
      <!-- <int> Number of partial page programming allowed -->
      <config name="NOP">1</config>
      <!-- <int> # die / package -->
      <config name="Die">1</config>
      <!-- <int> # plane / die -->
      <config name="Plane">2</config>
      <!-- <int> # block / plane -->
      <config name="Block">512</config>
      <!-- <int> # page / block -->
      <config name="Page">512</config>
      <!-- <int> page size in byte - data -->
      <config name="PageSize">16K</config>
      <!-- <int> page size in byte - spare -->
      <config name="SpareSize">1216</config>
      <!--
        <int> NAND type

        Possible values:
          0: Single Level Cell (level 0 of timing section should be valid)
          1: Multi Level Cell (level 0, 1 of timing section should be valid)
          2: Triple Level Cell (level 0 ~ 2 of timing section should be valid)
       -->
      <config name="NANDType">1</config>
      <!--
        <str> Page allocation method

        Set order of address (PPN) decomposition
        C for channel, W for way, D for die and P for package

        If you set page allocation strategy as CWDP, the PPN will look like:
        MSB .................. LSB
        [Plane][Die][Way][Channel]
        So that the consecutive page I/O goes to next channel.

        In SimpleSSD, first-level parallelism group should be channel in above
        example.
        Example) Each page in first-level parallelism group ->
                 Each page across the channel ->
                 Can be accessed in parallel

        See following paper for more details and impacts:
        M. Jung and M. Kandemir, "An Evaluation of Different Page Allocation
        Strateges on High-Speed SSDs," HotStorage 2012
       -->
      <config name="PageAllocation">CWDP</config>
      <!-- <time> NAND timing table -->
      <section name="timing">
        <!-- Address cycle to Data Load time -->
        <config name="tADL">70ns</config>
        <!-- CE_n Setup time -->
        <config name="tCS">20ns</config>
        <!-- Data Hold time -->
        <config name="tDH">280ps</config>
        <!-- Data Setup time -->
        <config name="tDS">280ps</config>
        <!-- RE_n Cycle time -->
        <config name="tRC">5ns</config>
        <!-- Ready to data output cycle -->
        <config name="tRR">20ns</config>
        <!-- WE_n high to SR[6] low -->
        <config name="tWB">100ns</config>
        <!-- WE_n Cycle time -->
        <config name="tWC">25ns</config>
        <!-- WE_n Pulse width -->
        <config name="tWP">11ns</config>
        <!-- Block erase time -->
        <config name="tBERS">5ms</config>
        <!-- Cache busy time -->
        <config name="tCBSY">35us</config>
        <!-- Dummy busy time (tPLRBSY/tPLPBSY/tPLEBSY) -->
        <config name="tDBSY">500ns</config>
        <!-- Read Cache busy time -->
        <config name="tRCBSY">3us</config>
        <!-- Page program time (SLC/MLC LSB/TLC LSB) -->
        <config name="tPROG" level="0">1250us</config>
        <!-- Page program time (MLC MSB/TLC CSB) -->
        <config name="tPROG" level="1">3ms</config>
        <!-- Page program time (TLC MSB) -->
        <config name="tPROG" level="2"></config>
        <!-- Page read time (SLC/MLC LSB/TLC LSB) -->
        <config name="tR" level="0">65us</config>
        <!-- Page read time (MLC MSB/TLC CSB) -->
        <config name="tR" level="1">110us</config>
        <!-- Page read time (TLC MSB) -->
        <config name="tR" level="2"></config>
      </section>
      <!--
        DRAM power configuration
        All values in <float>, current in uA, voltage in V.
       -->
      <section name="power">
        <!-- Array Read Current -->
        <config name="ICC1">25000</config>
        <!-- Array Program Current -->
        <config name="ICC2">25000</config>
        <!-- Array Erase Current -->
        <config name="ICC3">25000</config>
        <!-- I/O Burst Read Current -->
        <config name="ICC4R">10000</config>
        <!-- I/O Burst Write Current -->
        <config name="ICC4W">10000</config>
        <!-- Bus Idle Current -->
        <config name="ICC5">5000</config>
        <!-- Standby Current -->
        <config name="ISB">30</config>
        <!-- Voltage -->
        <config name="VCC">3.3</config>
      </section>
    </section>
  </section>
</simplessd>
